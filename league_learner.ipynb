{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = device(type='cpu')\n",
      "Input data: tensor([[1.0000e+00, 2.0200e+03, 2.0000e+00, 2.0180e+03, 3.0000e+00, 2.0190e+03,\n",
      "         4.0000e+00, 2.0140e+03, 5.0000e+00, 2.0170e+03, 6.0000e+00, 2.0230e+03,\n",
      "         7.0000e+00, 2.0200e+03, 8.0000e+00, 2.0060e+03, 9.0000e+00, 2.0200e+03,\n",
      "         1.0000e+01, 2.0230e+03, 1.1000e+01, 1.9860e+03, 1.2000e+01, 2.0050e+03,\n",
      "         1.3000e+01, 1.9770e+03, 1.4000e+01, 2.0190e+03, 1.5000e+01, 2.0190e+03,\n",
      "         1.6000e+01, 2.0150e+03, 1.7000e+01, 2.0150e+03, 1.8000e+01, 2.0190e+03,\n",
      "         1.9000e+01, 1.9690e+03, 1.0000e+00, 2.0000e+03, 2.0000e+00, 1.9730e+03,\n",
      "         3.0000e+00, 2.0210e+03, 4.0000e+00, 2.0080e+03, 5.0000e+00, 2.0240e+03,\n",
      "         6.0000e+00, 2.0110e+03, 7.0000e+00, 2.0220e+03, 8.0000e+00, 1.9650e+03,\n",
      "         9.0000e+00, 2.0210e+03, 1.0000e+01, 2.0140e+03, 1.1000e+01, 2.0040e+03,\n",
      "         1.2000e+01, 2.0190e+03, 1.3000e+01, 2.0210e+03, 1.4000e+01, 2.0170e+03,\n",
      "         1.5000e+01, 2.0240e+03, 1.6000e+01, 2.0100e+03, 1.7000e+01, 1.9920e+03,\n",
      "         1.8000e+01, 1.9890e+03, 1.9000e+01, 2.0200e+03, 2.0000e+01, 2.0120e+03,\n",
      "         1.0000e+00, 2.0160e+03, 2.0000e+00, 2.0160e+03, 3.0000e+00, 2.0200e+03,\n",
      "         4.0000e+00, 2.0200e+03, 5.0000e+00, 2.0080e+03, 6.0000e+00, 2.0230e+03,\n",
      "         7.0000e+00, 2.0160e+03, 8.0000e+00, 2.0140e+03, 9.0000e+00, 2.0000e+03,\n",
      "         1.0000e+01, 2.0170e+03, 1.1000e+01, 2.0120e+03, 1.2000e+01, 2.0230e+03,\n",
      "         1.3000e+01, 2.0200e+03, 1.4000e+01, 2.0170e+03, 1.5000e+01, 2.0180e+03,\n",
      "         1.6000e+01, 2.0230e+03, 1.7000e+01, 1.9730e+03, 1.8000e+01, 2.0200e+03,\n",
      "         1.9000e+01, 2.0180e+03, 2.0000e+01, 2.0150e+03, 1.0000e+00, 2.0170e+03,\n",
      "         2.0000e+00, 2.0160e+03, 3.0000e+00, 1.9720e+03, 4.0000e+00, 2.0000e+03,\n",
      "         5.0000e+00, 2.0050e+03, 6.0000e+00, 2.0220e+03, 7.0000e+00, 2.0170e+03,\n",
      "         8.0000e+00, 2.0180e+03, 9.0000e+00, 2.0180e+03, 1.0000e+01, 2.0230e+03,\n",
      "         1.1000e+01, 2.0190e+03, 1.2000e+01, 2.0190e+03, 1.3000e+01, 2.0190e+03,\n",
      "         1.4000e+01, 2.0230e+03, 1.5000e+01, 2.0190e+03, 1.6000e+01, 2.0160e+03,\n",
      "         1.7000e+01, 2.0230e+03, 1.8000e+01, 2.0080e+03, 1.9000e+01, 2.0230e+03,\n",
      "         2.0000e+01, 2.0120e+03, 1.0000e+00, 2.0170e+03, 2.0000e+00, 2.0230e+03,\n",
      "         3.0000e+00, 2.0200e+03, 4.0000e+00, 2.0220e+03, 5.0000e+00, 2.0210e+03,\n",
      "         6.0000e+00, 2.0000e+03, 7.0000e+00, 2.0080e+03, 8.0000e+00, 2.0200e+03,\n",
      "         9.0000e+00, 2.0000e+03, 1.0000e+01, 2.0200e+03, 1.1000e+01, 2.0230e+03,\n",
      "         1.2000e+01, 2.0200e+03, 1.3000e+01, 2.0200e+03, 1.4000e+01, 2.0150e+03,\n",
      "         1.5000e+01, 1.9980e+03, 1.6000e+01, 2.0190e+03, 1.7000e+01, 2.0220e+03,\n",
      "         1.8000e+01, 2.0190e+03, 1.9000e+01, 2.0210e+03, 2.0000e+01, 1.9970e+03,\n",
      "         1.0000e+00, 2.0130e+03, 2.0000e+00, 2.0200e+03, 3.0000e+00, 2.0220e+03,\n",
      "         4.0000e+00, 2.0130e+03, 5.0000e+00, 2.0140e+03, 6.0000e+00, 2.0190e+03,\n",
      "         7.0000e+00, 2.0180e+03, 8.0000e+00, 2.0180e+03, 9.0000e+00, 2.0230e+03,\n",
      "         1.0000e+01, 1.9960e+03, 1.1000e+01, 2.0050e+03, 1.2000e+01, 2.0150e+03,\n",
      "         1.3000e+01, 2.0210e+03, 1.4000e+01, 2.0210e+03, 1.5000e+01, 2.0170e+03,\n",
      "         1.6000e+01, 2.0190e+03, 1.7000e+01, 2.0010e+03, 1.8000e+01, 2.0000e+03,\n",
      "         1.0000e+00, 2.0190e+03, 2.0000e+00, 2.0160e+03, 3.0000e+00, 2.0190e+03,\n",
      "         4.0000e+00, 2.0180e+03, 5.0000e+00, 2.0230e+03, 6.0000e+00, 2.0230e+03,\n",
      "         7.0000e+00, 2.0130e+03, 8.0000e+00, 2.0230e+03, 9.0000e+00, 2.0220e+03,\n",
      "         1.0000e+01, 2.0080e+03, 1.1000e+01, 2.0130e+03, 1.2000e+01, 2.0120e+03,\n",
      "         1.3000e+01, 2.0040e+03, 1.4000e+01, 2.0140e+03, 1.5000e+01, 2.0230e+03,\n",
      "         1.6000e+01, 2.0190e+03, 1.0000e+00, 2.0100e+03, 2.0000e+00, 2.0090e+03,\n",
      "         3.0000e+00, 2.0220e+03, 4.0000e+00, 2.0130e+03, 5.0000e+00, 2.0200e+03,\n",
      "         6.0000e+00, 2.0220e+03, 7.0000e+00, 2.0190e+03, 8.0000e+00, 2.0200e+03,\n",
      "         9.0000e+00, 2.0210e+03, 1.0000e+01, 2.0190e+03, 1.1000e+01, 2.0220e+03,\n",
      "         1.2000e+01, 2.0170e+03, 1.3000e+01, 2.0230e+03, 1.4000e+01, 2.0150e+03,\n",
      "         1.5000e+01, 2.0180e+03, 1.6000e+01, 2.0180e+03, 1.7000e+01, 2.0210e+03,\n",
      "         1.8000e+01, 2.0220e+03, 1.9000e+01, 2.0230e+03, 1.0000e+00, 2.0170e+03,\n",
      "         2.0000e+00, 1.9970e+03, 3.0000e+00, 2.0160e+03, 4.0000e+00, 1.9670e+03,\n",
      "         5.0000e+00, 2.0220e+03, 6.0000e+00, 2.0180e+03, 7.0000e+00, 1.9990e+03,\n",
      "         8.0000e+00, 2.0130e+03, 9.0000e+00, 2.0240e+03, 1.0000e+01, 2.0210e+03,\n",
      "         1.1000e+01, 2.0180e+03, 1.2000e+01, 2.0240e+03, 1.3000e+01, 2.0190e+03,\n",
      "         1.4000e+01, 2.0150e+03, 1.5000e+01, 2.0160e+03, 1.6000e+01, 2.0060e+03,\n",
      "         1.7000e+01, 2.0210e+03, 1.8000e+01, 2.0190e+03, 1.9000e+01, 2.0230e+03,\n",
      "         1.0000e+00, 2.0140e+03, 2.0000e+00, 2.0230e+03, 3.0000e+00, 2.0120e+03,\n",
      "         4.0000e+00, 2.0180e+03, 5.0000e+00, 2.0130e+03, 6.0000e+00, 2.0170e+03,\n",
      "         7.0000e+00, 1.9790e+03, 8.0000e+00, 2.0230e+03, 9.0000e+00, 2.0210e+03,\n",
      "         1.0000e+01, 2.0080e+03, 1.1000e+01, 2.0220e+03, 1.2000e+01, 2.0200e+03,\n",
      "         1.3000e+01, 2.0200e+03, 1.4000e+01, 2.0080e+03, 1.5000e+01, 2.0160e+03,\n",
      "         1.6000e+01, 2.0160e+03, 1.7000e+01, 2.0200e+03, 1.8000e+01, 2.0070e+03,\n",
      "         1.9000e+01, 2.0230e+03]])\n",
      "Target rank: tensor([[12., 16.,  2.,  8.,  3., 18.,  4., 13.,  7.,  9.,  5., 15.,  1., 11.,\n",
      "         17., 14.,  6., 10., 19., 15., 12.,  9., 18.,  1.,  7.,  4., 20.,  8.,\n",
      "         19.,  2., 11., 10.,  3.,  5., 14., 17., 13.,  6., 16.,  7., 11.,  6.,\n",
      "          5.,  8., 18.,  3., 16., 14., 12., 13., 15.,  4.,  9.,  1., 10.,  2.,\n",
      "         20., 17., 19., 14.,  4., 19.,  3., 12., 17.,  8.,  5.,  2., 18., 13.,\n",
      "         20., 16.,  7.,  1., 10., 15.,  9., 11.,  6., 13., 19., 12.,  2., 11.,\n",
      "         20.,  5.,  6., 18., 10., 14.,  7.,  3.,  8., 15., 17.,  1., 16.,  9.,\n",
      "          4.,  4., 11., 16.,  6., 15.,  1., 10.,  2.,  9., 12.,  7.,  8., 18.,\n",
      "          3.,  5., 13., 14., 17.,  4., 13., 14.,  6., 11.,  2.,  5., 16.,  3.,\n",
      "         15., 10.,  7., 12.,  9.,  8.,  1.,  3., 12., 15.,  2., 16.,  4.,  9.,\n",
      "          7., 19.,  5.,  8.,  1., 11., 14.,  6., 18., 17., 10., 13., 11., 12.,\n",
      "          7.,  8.,  2.,  9., 14., 19.,  5.,  4.,  1., 16., 15., 18., 17.,  3.,\n",
      "         13.,  6., 10., 18., 14.,  4.,  9., 12.,  1., 17., 11.,  3., 15.,  7.,\n",
      "          2., 16., 10.,  5.,  6.,  8., 19., 13.]])\n"
     ]
    }
   ],
   "source": [
    "DEVICE: torch.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{DEVICE = }\")\n",
    "\n",
    "# read input and target data files\n",
    "input_data = []\n",
    "target_rank = []\n",
    "\n",
    "with open('input_data.txt', 'r') as f_input:\n",
    "    for line in f_input:\n",
    "        position, release_date = map(float, line.split()) \n",
    "        input_data.append([position, release_date])\n",
    "input_data_tensor = torch.tensor(input_data)\n",
    "input_data_tensor = input_data_tensor.view(1, -1)\n",
    "\n",
    "with open('target_ranks.txt', 'r') as f_target:\n",
    "    target_lines = f_target.readlines()\n",
    "target_rank = [float(target_line.strip()) for target_line in target_lines]\n",
    "target_rank_tensor = torch.tensor(target_rank)\n",
    "target_rank_tensor = target_rank_tensor.view(1, -1)\n",
    "\n",
    "print(\"Input data:\", input_data_tensor)\n",
    "print(\"Target rank:\", target_rank_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeagueNN(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:\n",
    "        super(LeagueNN, self).__init__()\n",
    "        # affine transformations\n",
    "        self.lin1 = nn.Linear(input_size, hidden_size) \n",
    "        # with nonlinearities in between\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # apply things in sequence\n",
    "        out = self.lin1(x.flatten(start_dim=1))\n",
    "        out = self.relu(out)\n",
    "        out = self.lin2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100000], Loss: 122599.0625\n",
      "Epoch [200/100000], Loss: 120044.8750\n",
      "Epoch [300/100000], Loss: 117543.8984\n",
      "Epoch [400/100000], Loss: 115095.0234\n",
      "Epoch [500/100000], Loss: 112697.1797\n",
      "Epoch [600/100000], Loss: 110349.2812\n",
      "Epoch [700/100000], Loss: 108050.3047\n",
      "Epoch [800/100000], Loss: 105799.2344\n",
      "Epoch [900/100000], Loss: 103595.0312\n",
      "Epoch [1000/100000], Loss: 101436.7656\n",
      "Epoch [1100/100000], Loss: 99323.4766\n",
      "Epoch [1200/100000], Loss: 97254.2031\n",
      "Epoch [1300/100000], Loss: 95228.0391\n",
      "Epoch [1400/100000], Loss: 93244.0859\n",
      "Epoch [1500/100000], Loss: 91301.4844\n",
      "Epoch [1600/100000], Loss: 89399.3359\n",
      "Epoch [1700/100000], Loss: 87536.8203\n",
      "Epoch [1800/100000], Loss: 85713.1016\n",
      "Epoch [1900/100000], Loss: 83927.3828\n",
      "Epoch [2000/100000], Loss: 82178.8750\n",
      "Epoch [2100/100000], Loss: 80466.7891\n",
      "Epoch [2200/100000], Loss: 78790.3594\n",
      "Epoch [2300/100000], Loss: 77148.8828\n",
      "Epoch [2400/100000], Loss: 75541.5781\n",
      "Epoch [2500/100000], Loss: 73967.7734\n",
      "Epoch [2600/100000], Loss: 72426.7500\n",
      "Epoch [2700/100000], Loss: 70917.8359\n",
      "Epoch [2800/100000], Loss: 69440.3594\n",
      "Epoch [2900/100000], Loss: 67993.6641\n",
      "Epoch [3000/100000], Loss: 66577.1016\n",
      "Epoch [3100/100000], Loss: 65190.0586\n",
      "Epoch [3200/100000], Loss: 63831.9102\n",
      "Epoch [3300/100000], Loss: 62502.0625\n",
      "Epoch [3400/100000], Loss: 61199.9141\n",
      "Epoch [3500/100000], Loss: 59924.8945\n",
      "Epoch [3600/100000], Loss: 58676.4414\n",
      "Epoch [3700/100000], Loss: 57454.0000\n",
      "Epoch [3800/100000], Loss: 56257.0195\n",
      "Epoch [3900/100000], Loss: 55084.9844\n",
      "Epoch [4000/100000], Loss: 53937.3594\n",
      "Epoch [4100/100000], Loss: 52813.6484\n",
      "Epoch [4200/100000], Loss: 51713.3438\n",
      "Epoch [4300/100000], Loss: 50635.9688\n",
      "Epoch [4400/100000], Loss: 49581.0312\n",
      "Epoch [4500/100000], Loss: 48548.0781\n",
      "Epoch [4600/100000], Loss: 47536.6484\n",
      "Epoch [4700/100000], Loss: 46546.2891\n",
      "Epoch [4800/100000], Loss: 45576.5586\n",
      "Epoch [4900/100000], Loss: 44627.0312\n",
      "Epoch [5000/100000], Loss: 43697.2891\n",
      "Epoch [5100/100000], Loss: 42786.9141\n",
      "Epoch [5200/100000], Loss: 41895.5039\n",
      "Epoch [5300/100000], Loss: 41022.6719\n",
      "Epoch [5400/100000], Loss: 40168.0156\n",
      "Epoch [5500/100000], Loss: 39331.1719\n",
      "Epoch [5600/100000], Loss: 38511.7617\n",
      "Epoch [5700/100000], Loss: 37709.4141\n",
      "Epoch [5800/100000], Loss: 36923.7930\n",
      "Epoch [5900/100000], Loss: 36154.5312\n",
      "Epoch [6000/100000], Loss: 35401.3047\n",
      "Epoch [6100/100000], Loss: 34663.7617\n",
      "Epoch [6200/100000], Loss: 33941.5938\n",
      "Epoch [6300/100000], Loss: 33234.4688\n",
      "Epoch [6400/100000], Loss: 32542.0703\n",
      "Epoch [6500/100000], Loss: 31864.0996\n",
      "Epoch [6600/100000], Loss: 31200.2578\n",
      "Epoch [6700/100000], Loss: 30550.2422\n",
      "Epoch [6800/100000], Loss: 29913.7676\n",
      "Epoch [6900/100000], Loss: 29290.5547\n",
      "Epoch [7000/100000], Loss: 28680.3262\n",
      "Epoch [7100/100000], Loss: 28082.8105\n",
      "Epoch [7200/100000], Loss: 27497.7422\n",
      "Epoch [7300/100000], Loss: 26924.8633\n",
      "Epoch [7400/100000], Loss: 26363.9180\n",
      "Epoch [7500/100000], Loss: 25814.6602\n",
      "Epoch [7600/100000], Loss: 25276.8477\n",
      "Epoch [7700/100000], Loss: 24750.2402\n",
      "Epoch [7800/100000], Loss: 24234.6035\n",
      "Epoch [7900/100000], Loss: 23729.7051\n",
      "Epoch [8000/100000], Loss: 23235.3281\n",
      "Epoch [8100/100000], Loss: 22751.2559\n",
      "Epoch [8200/100000], Loss: 22277.2598\n",
      "Epoch [8300/100000], Loss: 21813.1465\n",
      "Epoch [8400/100000], Loss: 21358.6992\n",
      "Epoch [8500/100000], Loss: 20913.7188\n",
      "Epoch [8600/100000], Loss: 20478.0098\n",
      "Epoch [8700/100000], Loss: 20051.3770\n",
      "Epoch [8800/100000], Loss: 19633.6348\n",
      "Epoch [8900/100000], Loss: 19224.5938\n",
      "Epoch [9000/100000], Loss: 18824.0742\n",
      "Epoch [9100/100000], Loss: 18431.9004\n",
      "Epoch [9200/100000], Loss: 18047.8965\n",
      "Epoch [9300/100000], Loss: 17671.8926\n",
      "Epoch [9400/100000], Loss: 17303.7266\n",
      "Epoch [9500/100000], Loss: 16943.2246\n",
      "Epoch [9600/100000], Loss: 16590.2363\n",
      "Epoch [9700/100000], Loss: 16244.6016\n",
      "Epoch [9800/100000], Loss: 15906.1660\n",
      "Epoch [9900/100000], Loss: 15574.7812\n",
      "Epoch [10000/100000], Loss: 15250.3027\n",
      "Epoch [10100/100000], Loss: 14932.5840\n",
      "Epoch [10200/100000], Loss: 14621.4814\n",
      "Epoch [10300/100000], Loss: 14316.8643\n",
      "Epoch [10400/100000], Loss: 14018.5908\n",
      "Epoch [10500/100000], Loss: 13726.5342\n",
      "Epoch [10600/100000], Loss: 13440.5596\n",
      "Epoch [10700/100000], Loss: 13160.5430\n",
      "Epoch [10800/100000], Loss: 12886.3604\n",
      "Epoch [10900/100000], Loss: 12617.8906\n",
      "Epoch [11000/100000], Loss: 12355.0146\n",
      "Epoch [11100/100000], Loss: 12097.6143\n",
      "Epoch [11200/100000], Loss: 11845.5771\n",
      "Epoch [11300/100000], Loss: 11598.7910\n",
      "Epoch [11400/100000], Loss: 11357.1445\n",
      "Epoch [11500/100000], Loss: 11120.5342\n",
      "Epoch [11600/100000], Loss: 10888.8525\n",
      "Epoch [11700/100000], Loss: 10661.9971\n",
      "Epoch [11800/100000], Loss: 10439.8691\n",
      "Epoch [11900/100000], Loss: 10222.3691\n",
      "Epoch [12000/100000], Loss: 10009.3984\n",
      "Epoch [12100/100000], Loss: 9800.8662\n",
      "Epoch [12200/100000], Loss: 9596.6797\n",
      "Epoch [12300/100000], Loss: 9396.7451\n",
      "Epoch [12400/100000], Loss: 9200.9775\n",
      "Epoch [12500/100000], Loss: 9009.2861\n",
      "Epoch [12600/100000], Loss: 8821.5908\n",
      "Epoch [12700/100000], Loss: 8637.8037\n",
      "Epoch [12800/100000], Loss: 8457.8477\n",
      "Epoch [12900/100000], Loss: 8281.6396\n",
      "Epoch [13000/100000], Loss: 8109.1021\n",
      "Epoch [13100/100000], Loss: 7940.1592\n",
      "Epoch [13200/100000], Loss: 7774.7368\n",
      "Epoch [13300/100000], Loss: 7612.7617\n",
      "Epoch [13400/100000], Loss: 7454.1592\n",
      "Epoch [13500/100000], Loss: 7298.8618\n",
      "Epoch [13600/100000], Loss: 7146.7998\n",
      "Epoch [13700/100000], Loss: 6997.9058\n",
      "Epoch [13800/100000], Loss: 6852.1138\n",
      "Epoch [13900/100000], Loss: 6709.3594\n",
      "Epoch [14000/100000], Loss: 6569.5791\n",
      "Epoch [14100/100000], Loss: 6432.7104\n",
      "Epoch [14200/100000], Loss: 6298.6934\n",
      "Epoch [14300/100000], Loss: 6167.4692\n",
      "Epoch [14400/100000], Loss: 6038.9775\n",
      "Epoch [14500/100000], Loss: 5913.1636\n",
      "Epoch [14600/100000], Loss: 5789.9712\n",
      "Epoch [14700/100000], Loss: 5669.3442\n",
      "Epoch [14800/100000], Loss: 5551.2310\n",
      "Epoch [14900/100000], Loss: 5435.5786\n",
      "Epoch [15000/100000], Loss: 5322.3354\n",
      "Epoch [15100/100000], Loss: 5211.4521\n",
      "Epoch [15200/100000], Loss: 5102.8779\n",
      "Epoch [15300/100000], Loss: 4996.5669\n",
      "Epoch [15400/100000], Loss: 4892.4697\n",
      "Epoch [15500/100000], Loss: 4790.5415\n",
      "Epoch [15600/100000], Loss: 4690.7373\n",
      "Epoch [15700/100000], Loss: 4593.0117\n",
      "Epoch [15800/100000], Loss: 4497.3223\n",
      "Epoch [15900/100000], Loss: 4403.6270\n",
      "Epoch [16000/100000], Loss: 4311.8833\n",
      "Epoch [16100/100000], Loss: 4222.0508\n",
      "Epoch [16200/100000], Loss: 4134.0903\n",
      "Epoch [16300/100000], Loss: 4047.9614\n",
      "Epoch [16400/100000], Loss: 3963.6282\n",
      "Epoch [16500/100000], Loss: 3881.0510\n",
      "Epoch [16600/100000], Loss: 3800.1948\n",
      "Epoch [16700/100000], Loss: 3721.0225\n",
      "Epoch [16800/100000], Loss: 3643.4998\n",
      "Epoch [16900/100000], Loss: 3567.5925\n",
      "Epoch [17000/100000], Loss: 3493.2664\n",
      "Epoch [17100/100000], Loss: 3420.4888\n",
      "Epoch [17200/100000], Loss: 3349.2275\n",
      "Epoch [17300/100000], Loss: 3279.4509\n",
      "Epoch [17400/100000], Loss: 3211.1282\n",
      "Epoch [17500/100000], Loss: 3144.2283\n",
      "Epoch [17600/100000], Loss: 3078.7224\n",
      "Epoch [17700/100000], Loss: 3014.5815\n",
      "Epoch [17800/100000], Loss: 2951.7766\n",
      "Epoch [17900/100000], Loss: 2890.2805\n",
      "Epoch [18000/100000], Loss: 2830.0652\n",
      "Epoch [18100/100000], Loss: 2771.1045\n",
      "Epoch [18200/100000], Loss: 2713.3728\n",
      "Epoch [18300/100000], Loss: 2656.8430\n",
      "Epoch [18400/100000], Loss: 2601.4912\n",
      "Epoch [18500/100000], Loss: 2547.2927\n",
      "Epoch [18600/100000], Loss: 2494.2234\n",
      "Epoch [18700/100000], Loss: 2442.2598\n",
      "Epoch [18800/100000], Loss: 2391.3782\n",
      "Epoch [18900/100000], Loss: 2341.5571\n",
      "Epoch [19000/100000], Loss: 2292.7739\n",
      "Epoch [19100/100000], Loss: 2245.0073\n",
      "Epoch [19200/100000], Loss: 2198.2356\n",
      "Epoch [19300/100000], Loss: 2152.4382\n",
      "Epoch [19400/100000], Loss: 2107.5950\n",
      "Epoch [19500/100000], Loss: 2063.6860\n",
      "Epoch [19600/100000], Loss: 2020.6923\n",
      "Epoch [19700/100000], Loss: 1978.5934\n",
      "Epoch [19800/100000], Loss: 1937.3721\n",
      "Epoch [19900/100000], Loss: 1897.0096\n",
      "Epoch [20000/100000], Loss: 1857.4882\n",
      "Epoch [20100/100000], Loss: 1818.7898\n",
      "Epoch [20200/100000], Loss: 1780.8978\n",
      "Epoch [20300/100000], Loss: 1743.7953\n",
      "Epoch [20400/100000], Loss: 1707.4655\n",
      "Epoch [20500/100000], Loss: 1671.8929\n",
      "Epoch [20600/100000], Loss: 1637.0610\n",
      "Epoch [20700/100000], Loss: 1602.9551\n",
      "Epoch [20800/100000], Loss: 1569.5596\n",
      "Epoch [20900/100000], Loss: 1536.8602\n",
      "Epoch [21000/100000], Loss: 1504.8418\n",
      "Epoch [21100/100000], Loss: 1473.4905\n",
      "Epoch [21200/100000], Loss: 1442.7922\n",
      "Epoch [21300/100000], Loss: 1412.7338\n",
      "Epoch [21400/100000], Loss: 1383.3011\n",
      "Epoch [21500/100000], Loss: 1354.4819\n",
      "Epoch [21600/100000], Loss: 1326.2632\n",
      "Epoch [21700/100000], Loss: 1298.6322\n",
      "Epoch [21800/100000], Loss: 1271.5770\n",
      "Epoch [21900/100000], Loss: 1245.0856\n",
      "Epoch [22000/100000], Loss: 1219.1458\n",
      "Epoch [22100/100000], Loss: 1193.7465\n",
      "Epoch [22200/100000], Loss: 1168.8765\n",
      "Epoch [22300/100000], Loss: 1144.5245\n",
      "Epoch [22400/100000], Loss: 1120.6798\n",
      "Epoch [22500/100000], Loss: 1097.3319\n",
      "Epoch [22600/100000], Loss: 1074.4705\n",
      "Epoch [22700/100000], Loss: 1052.0853\n",
      "Epoch [22800/100000], Loss: 1030.1667\n",
      "Epoch [22900/100000], Loss: 1008.7045\n",
      "Epoch [23000/100000], Loss: 987.6894\n",
      "Epoch [23100/100000], Loss: 967.1124\n",
      "Epoch [23200/100000], Loss: 946.9638\n",
      "Epoch [23300/100000], Loss: 927.2350\n",
      "Epoch [23400/100000], Loss: 907.9175\n",
      "Epoch [23500/100000], Loss: 889.0022\n",
      "Epoch [23600/100000], Loss: 870.4811\n",
      "Epoch [23700/100000], Loss: 852.3457\n",
      "Epoch [23800/100000], Loss: 834.5883\n",
      "Epoch [23900/100000], Loss: 817.2007\n",
      "Epoch [24000/100000], Loss: 800.1755\n",
      "Epoch [24100/100000], Loss: 783.5049\n",
      "Epoch [24200/100000], Loss: 767.1818\n",
      "Epoch [24300/100000], Loss: 751.1985\n",
      "Epoch [24400/100000], Loss: 735.5483\n",
      "Epoch [24500/100000], Loss: 720.2241\n",
      "Epoch [24600/100000], Loss: 705.2192\n",
      "Epoch [24700/100000], Loss: 690.5269\n",
      "Epoch [24800/100000], Loss: 676.1407\n",
      "Epoch [24900/100000], Loss: 662.0541\n",
      "Epoch [25000/100000], Loss: 648.2612\n",
      "Epoch [25100/100000], Loss: 634.7555\n",
      "Epoch [25200/100000], Loss: 621.5312\n",
      "Epoch [25300/100000], Loss: 608.5825\n",
      "Epoch [25400/100000], Loss: 595.9034\n",
      "Epoch [25500/100000], Loss: 583.4886\n",
      "Epoch [25600/100000], Loss: 571.3325\n",
      "Epoch [25700/100000], Loss: 559.4295\n",
      "Epoch [25800/100000], Loss: 547.7745\n",
      "Epoch [25900/100000], Loss: 536.3624\n",
      "Epoch [26000/100000], Loss: 525.1880\n",
      "Epoch [26100/100000], Loss: 514.2464\n",
      "Epoch [26200/100000], Loss: 503.5328\n",
      "Epoch [26300/100000], Loss: 493.0423\n",
      "Epoch [26400/100000], Loss: 482.7705\n",
      "Epoch [26500/100000], Loss: 472.7126\n",
      "Epoch [26600/100000], Loss: 462.8642\n",
      "Epoch [26700/100000], Loss: 453.2211\n",
      "Epoch [26800/100000], Loss: 443.7788\n",
      "Epoch [26900/100000], Loss: 434.5333\n",
      "Epoch [27000/100000], Loss: 425.4804\n",
      "Epoch [27100/100000], Loss: 416.6161\n",
      "Epoch [27200/100000], Loss: 407.9365\n",
      "Epoch [27300/100000], Loss: 399.4377\n",
      "Epoch [27400/100000], Loss: 391.1159\n",
      "Epoch [27500/100000], Loss: 382.9676\n",
      "Epoch [27600/100000], Loss: 374.9889\n",
      "Epoch [27700/100000], Loss: 367.1765\n",
      "Epoch [27800/100000], Loss: 359.5269\n",
      "Epoch [27900/100000], Loss: 352.0367\n",
      "Epoch [28000/100000], Loss: 344.7024\n",
      "Epoch [28100/100000], Loss: 337.5210\n",
      "Epoch [28200/100000], Loss: 330.4892\n",
      "Epoch [28300/100000], Loss: 323.6039\n",
      "Epoch [28400/100000], Loss: 316.8621\n",
      "Epoch [28500/100000], Loss: 310.2607\n",
      "Epoch [28600/100000], Loss: 303.7968\n",
      "Epoch [28700/100000], Loss: 297.4676\n",
      "Epoch [28800/100000], Loss: 291.2702\n",
      "Epoch [28900/100000], Loss: 285.2020\n",
      "Epoch [29000/100000], Loss: 279.2602\n",
      "Epoch [29100/100000], Loss: 273.4422\n",
      "Epoch [29200/100000], Loss: 267.7454\n",
      "Epoch [29300/100000], Loss: 262.1673\n",
      "Epoch [29400/100000], Loss: 256.7054\n",
      "Epoch [29500/100000], Loss: 251.3573\n",
      "Epoch [29600/100000], Loss: 246.1206\n",
      "Epoch [29700/100000], Loss: 240.9930\n",
      "Epoch [29800/100000], Loss: 235.9722\n",
      "Epoch [29900/100000], Loss: 231.0561\n",
      "Epoch [30000/100000], Loss: 226.2423\n",
      "Epoch [30100/100000], Loss: 221.5289\n",
      "Epoch [30200/100000], Loss: 216.9136\n",
      "Epoch [30300/100000], Loss: 212.3945\n",
      "Epoch [30400/100000], Loss: 207.9696\n",
      "Epoch [30500/100000], Loss: 203.6368\n",
      "Epoch [30600/100000], Loss: 199.3943\n",
      "Epoch [30700/100000], Loss: 195.2402\n",
      "Epoch [30800/100000], Loss: 191.1726\n",
      "Epoch [30900/100000], Loss: 187.1898\n",
      "Epoch [31000/100000], Loss: 183.2899\n",
      "Epoch [31100/100000], Loss: 179.4713\n",
      "Epoch [31200/100000], Loss: 175.7323\n",
      "Epoch [31300/100000], Loss: 172.0712\n",
      "Epoch [31400/100000], Loss: 168.4863\n",
      "Epoch [31500/100000], Loss: 164.9761\n",
      "Epoch [31600/100000], Loss: 161.5390\n",
      "Epoch [31700/100000], Loss: 158.1736\n",
      "Epoch [31800/100000], Loss: 154.8783\n",
      "Epoch [31900/100000], Loss: 151.6516\n",
      "Epoch [32000/100000], Loss: 148.4921\n",
      "Epoch [32100/100000], Loss: 145.3985\n",
      "Epoch [32200/100000], Loss: 142.3693\n",
      "Epoch [32300/100000], Loss: 139.4032\n",
      "Epoch [32400/100000], Loss: 136.4989\n",
      "Epoch [32500/100000], Loss: 133.6552\n",
      "Epoch [32600/100000], Loss: 130.8706\n",
      "Epoch [32700/100000], Loss: 128.1441\n",
      "Epoch [32800/100000], Loss: 125.4744\n",
      "Epoch [32900/100000], Loss: 122.8603\n",
      "Epoch [33000/100000], Loss: 120.3007\n",
      "Epoch [33100/100000], Loss: 117.7944\n",
      "Epoch [33200/100000], Loss: 115.3403\n",
      "Epoch [33300/100000], Loss: 112.9373\n",
      "Epoch [33400/100000], Loss: 110.5845\n",
      "Epoch [33500/100000], Loss: 108.2806\n",
      "Epoch [33600/100000], Loss: 106.0247\n",
      "Epoch [33700/100000], Loss: 103.8158\n",
      "Epoch [33800/100000], Loss: 101.6529\n",
      "Epoch [33900/100000], Loss: 99.5352\n",
      "Epoch [34000/100000], Loss: 97.4615\n",
      "Epoch [34100/100000], Loss: 95.4310\n",
      "Epoch [34200/100000], Loss: 93.4428\n",
      "Epoch [34300/100000], Loss: 91.4961\n",
      "Epoch [34400/100000], Loss: 89.5899\n",
      "Epoch [34500/100000], Loss: 87.7234\n",
      "Epoch [34600/100000], Loss: 85.8958\n",
      "Epoch [34700/100000], Loss: 84.1063\n",
      "Epoch [34800/100000], Loss: 82.3540\n",
      "Epoch [34900/100000], Loss: 80.6383\n",
      "Epoch [35000/100000], Loss: 78.9583\n",
      "Epoch [35100/100000], Loss: 77.3133\n",
      "Epoch [35200/100000], Loss: 75.7026\n",
      "Epoch [35300/100000], Loss: 74.1254\n",
      "Epoch [35400/100000], Loss: 72.5811\n",
      "Epoch [35500/100000], Loss: 71.0690\n",
      "Epoch [35600/100000], Loss: 69.5884\n",
      "Epoch [35700/100000], Loss: 68.1386\n",
      "Epoch [35800/100000], Loss: 66.7190\n",
      "Epoch [35900/100000], Loss: 65.3290\n",
      "Epoch [36000/100000], Loss: 63.9680\n",
      "Epoch [36100/100000], Loss: 62.6353\n",
      "Epoch [36200/100000], Loss: 61.3304\n",
      "Epoch [36300/100000], Loss: 60.0526\n",
      "Epoch [36400/100000], Loss: 58.8015\n",
      "Epoch [36500/100000], Loss: 57.5765\n",
      "Epoch [36600/100000], Loss: 56.3769\n",
      "Epoch [36700/100000], Loss: 55.2024\n",
      "Epoch [36800/100000], Loss: 54.0523\n",
      "Epoch [36900/100000], Loss: 52.9262\n",
      "Epoch [37000/100000], Loss: 51.8236\n",
      "Epoch [37100/100000], Loss: 50.7439\n",
      "Epoch [37200/100000], Loss: 49.6867\n",
      "Epoch [37300/100000], Loss: 48.6516\n",
      "Epoch [37400/100000], Loss: 47.6380\n",
      "Epoch [37500/100000], Loss: 46.6455\n",
      "Epoch [37600/100000], Loss: 45.6737\n",
      "Epoch [37700/100000], Loss: 44.7222\n",
      "Epoch [37800/100000], Loss: 43.7904\n",
      "Epoch [37900/100000], Loss: 42.8781\n",
      "Epoch [38000/100000], Loss: 41.9848\n",
      "Epoch [38100/100000], Loss: 41.1101\n",
      "Epoch [38200/100000], Loss: 40.2536\n",
      "Epoch [38300/100000], Loss: 39.4150\n",
      "Epoch [38400/100000], Loss: 38.5938\n",
      "Epoch [38500/100000], Loss: 37.7898\n",
      "Epoch [38600/100000], Loss: 37.0025\n",
      "Epoch [38700/100000], Loss: 36.2316\n",
      "Epoch [38800/100000], Loss: 35.4768\n",
      "Epoch [38900/100000], Loss: 34.7376\n",
      "Epoch [39000/100000], Loss: 34.0139\n",
      "Epoch [39100/100000], Loss: 33.3053\n",
      "Epoch [39200/100000], Loss: 32.6114\n",
      "Epoch [39300/100000], Loss: 31.9320\n",
      "Epoch [39400/100000], Loss: 31.2668\n",
      "Epoch [39500/100000], Loss: 30.6154\n",
      "Epoch [39600/100000], Loss: 29.9775\n",
      "Epoch [39700/100000], Loss: 29.3530\n",
      "Epoch [39800/100000], Loss: 28.7414\n",
      "Epoch [39900/100000], Loss: 28.1427\n",
      "Epoch [40000/100000], Loss: 27.5563\n",
      "Epoch [40100/100000], Loss: 26.9823\n",
      "Epoch [40200/100000], Loss: 26.4201\n",
      "Epoch [40300/100000], Loss: 25.8697\n",
      "Epoch [40400/100000], Loss: 25.3307\n",
      "Epoch [40500/100000], Loss: 24.8030\n",
      "Epoch [40600/100000], Loss: 24.2863\n",
      "Epoch [40700/100000], Loss: 23.7803\n",
      "Epoch [40800/100000], Loss: 23.2849\n",
      "Epoch [40900/100000], Loss: 22.7997\n",
      "Epoch [41000/100000], Loss: 22.3247\n",
      "Epoch [41100/100000], Loss: 21.8596\n",
      "Epoch [41200/100000], Loss: 21.4042\n",
      "Epoch [41300/100000], Loss: 20.9583\n",
      "Epoch [41400/100000], Loss: 20.5217\n",
      "Epoch [41500/100000], Loss: 20.0941\n",
      "Epoch [41600/100000], Loss: 19.6755\n",
      "Epoch [41700/100000], Loss: 19.2656\n",
      "Epoch [41800/100000], Loss: 18.8642\n",
      "Epoch [41900/100000], Loss: 18.4712\n",
      "Epoch [42000/100000], Loss: 18.0864\n",
      "Epoch [42100/100000], Loss: 17.7096\n",
      "Epoch [42200/100000], Loss: 17.3406\n",
      "Epoch [42300/100000], Loss: 16.9793\n",
      "Epoch [42400/100000], Loss: 16.6256\n",
      "Epoch [42500/100000], Loss: 16.2792\n",
      "Epoch [42600/100000], Loss: 15.9401\n",
      "Epoch [42700/100000], Loss: 15.6080\n",
      "Epoch [42800/100000], Loss: 15.2828\n",
      "Epoch [42900/100000], Loss: 14.9644\n",
      "Epoch [43000/100000], Loss: 14.6526\n",
      "Epoch [43100/100000], Loss: 14.3474\n",
      "Epoch [43200/100000], Loss: 14.0485\n",
      "Epoch [43300/100000], Loss: 13.7558\n",
      "Epoch [43400/100000], Loss: 13.4692\n",
      "Epoch [43500/100000], Loss: 13.1886\n",
      "Epoch [43600/100000], Loss: 12.9138\n",
      "Epoch [43700/100000], Loss: 12.6448\n",
      "Epoch [43800/100000], Loss: 12.3813\n",
      "Epoch [43900/100000], Loss: 12.1234\n",
      "Epoch [44000/100000], Loss: 11.8708\n",
      "Epoch [44100/100000], Loss: 11.6235\n",
      "Epoch [44200/100000], Loss: 11.3814\n",
      "Epoch [44300/100000], Loss: 11.1442\n",
      "Epoch [44400/100000], Loss: 10.9121\n",
      "Epoch [44500/100000], Loss: 10.6847\n",
      "Epoch [44600/100000], Loss: 10.4621\n",
      "Epoch [44700/100000], Loss: 10.2442\n",
      "Epoch [44800/100000], Loss: 10.0307\n",
      "Epoch [44900/100000], Loss: 9.8218\n",
      "Epoch [45000/100000], Loss: 9.6171\n",
      "Epoch [45100/100000], Loss: 9.4168\n",
      "Epoch [45200/100000], Loss: 9.2206\n",
      "Epoch [45300/100000], Loss: 9.0285\n",
      "Epoch [45400/100000], Loss: 8.8404\n",
      "Epoch [45500/100000], Loss: 8.6562\n",
      "Epoch [45600/100000], Loss: 8.4759\n",
      "Epoch [45700/100000], Loss: 8.2993\n",
      "Epoch [45800/100000], Loss: 8.1264\n",
      "Epoch [45900/100000], Loss: 7.9571\n",
      "Epoch [46000/100000], Loss: 7.7913\n",
      "Epoch [46100/100000], Loss: 7.6290\n",
      "Epoch [46200/100000], Loss: 7.4701\n",
      "Epoch [46300/100000], Loss: 7.3144\n",
      "Epoch [46400/100000], Loss: 7.1620\n",
      "Epoch [46500/100000], Loss: 7.0128\n",
      "Epoch [46600/100000], Loss: 6.8667\n",
      "Epoch [46700/100000], Loss: 6.7237\n",
      "Epoch [46800/100000], Loss: 6.5836\n",
      "Epoch [46900/100000], Loss: 6.4464\n",
      "Epoch [47000/100000], Loss: 6.3121\n",
      "Epoch [47100/100000], Loss: 6.1806\n",
      "Epoch [47200/100000], Loss: 6.0519\n",
      "Epoch [47300/100000], Loss: 5.9258\n",
      "Epoch [47400/100000], Loss: 5.8023\n",
      "Epoch [47500/100000], Loss: 5.6814\n",
      "Epoch [47600/100000], Loss: 5.5631\n",
      "Epoch [47700/100000], Loss: 5.4472\n",
      "Epoch [47800/100000], Loss: 5.3337\n",
      "Epoch [47900/100000], Loss: 5.2226\n",
      "Epoch [48000/100000], Loss: 5.1138\n",
      "Epoch [48100/100000], Loss: 5.0072\n",
      "Epoch [48200/100000], Loss: 4.9029\n",
      "Epoch [48300/100000], Loss: 4.8008\n",
      "Epoch [48400/100000], Loss: 4.7007\n",
      "Epoch [48500/100000], Loss: 4.6028\n",
      "Epoch [48600/100000], Loss: 4.5069\n",
      "Epoch [48700/100000], Loss: 4.4130\n",
      "Epoch [48800/100000], Loss: 4.3211\n",
      "Epoch [48900/100000], Loss: 4.2311\n",
      "Epoch [49000/100000], Loss: 4.1429\n",
      "Epoch [49100/100000], Loss: 4.0566\n",
      "Epoch [49200/100000], Loss: 3.9721\n",
      "Epoch [49300/100000], Loss: 3.8893\n",
      "Epoch [49400/100000], Loss: 3.8083\n",
      "Epoch [49500/100000], Loss: 3.7290\n",
      "Epoch [49600/100000], Loss: 3.6513\n",
      "Epoch [49700/100000], Loss: 3.5752\n",
      "Epoch [49800/100000], Loss: 3.5007\n",
      "Epoch [49900/100000], Loss: 3.4278\n",
      "Epoch [50000/100000], Loss: 3.3564\n",
      "Epoch [50100/100000], Loss: 3.2864\n",
      "Epoch [50200/100000], Loss: 3.2180\n",
      "Epoch [50300/100000], Loss: 3.1509\n",
      "Epoch [50400/100000], Loss: 3.0853\n",
      "Epoch [50500/100000], Loss: 3.0210\n",
      "Epoch [50600/100000], Loss: 2.9581\n",
      "Epoch [50700/100000], Loss: 2.8964\n",
      "Epoch [50800/100000], Loss: 2.8361\n",
      "Epoch [50900/100000], Loss: 2.7770\n",
      "Epoch [51000/100000], Loss: 2.7192\n",
      "Epoch [51100/100000], Loss: 2.6625\n",
      "Epoch [51200/100000], Loss: 2.6070\n",
      "Epoch [51300/100000], Loss: 2.5527\n",
      "Epoch [51400/100000], Loss: 2.4995\n",
      "Epoch [51500/100000], Loss: 2.4475\n",
      "Epoch [51600/100000], Loss: 2.3965\n",
      "Epoch [51700/100000], Loss: 2.3466\n",
      "Epoch [51800/100000], Loss: 2.2977\n",
      "Epoch [51900/100000], Loss: 2.2498\n",
      "Epoch [52000/100000], Loss: 2.2029\n",
      "Epoch [52100/100000], Loss: 2.1570\n",
      "Epoch [52200/100000], Loss: 2.1121\n",
      "Epoch [52300/100000], Loss: 2.0681\n",
      "Epoch [52400/100000], Loss: 2.0250\n",
      "Epoch [52500/100000], Loss: 1.9828\n",
      "Epoch [52600/100000], Loss: 1.9415\n",
      "Epoch [52700/100000], Loss: 1.9011\n",
      "Epoch [52800/100000], Loss: 1.8615\n",
      "Epoch [52900/100000], Loss: 1.8227\n",
      "Epoch [53000/100000], Loss: 1.7847\n",
      "Epoch [53100/100000], Loss: 1.7475\n",
      "Epoch [53200/100000], Loss: 1.7111\n",
      "Epoch [53300/100000], Loss: 1.6755\n",
      "Epoch [53400/100000], Loss: 1.6406\n",
      "Epoch [53500/100000], Loss: 1.6064\n",
      "Epoch [53600/100000], Loss: 1.5729\n",
      "Epoch [53700/100000], Loss: 1.5401\n",
      "Epoch [53800/100000], Loss: 1.5081\n",
      "Epoch [53900/100000], Loss: 1.4766\n",
      "Epoch [54000/100000], Loss: 1.4459\n",
      "Epoch [54100/100000], Loss: 1.4158\n",
      "Epoch [54200/100000], Loss: 1.3863\n",
      "Epoch [54300/100000], Loss: 1.3574\n",
      "Epoch [54400/100000], Loss: 1.3291\n",
      "Epoch [54500/100000], Loss: 1.3014\n",
      "Epoch [54600/100000], Loss: 1.2743\n",
      "Epoch [54700/100000], Loss: 1.2477\n",
      "Epoch [54800/100000], Loss: 1.2218\n",
      "Epoch [54900/100000], Loss: 1.1963\n",
      "Epoch [55000/100000], Loss: 1.1714\n",
      "Epoch [55100/100000], Loss: 1.1470\n",
      "Epoch [55200/100000], Loss: 1.1231\n",
      "Epoch [55300/100000], Loss: 1.0997\n",
      "Epoch [55400/100000], Loss: 1.0768\n",
      "Epoch [55500/100000], Loss: 1.0543\n",
      "Epoch [55600/100000], Loss: 1.0324\n",
      "Epoch [55700/100000], Loss: 1.0109\n",
      "Epoch [55800/100000], Loss: 0.9898\n",
      "Epoch [55900/100000], Loss: 0.9692\n",
      "Epoch [56000/100000], Loss: 0.9490\n",
      "Epoch [56100/100000], Loss: 0.9292\n",
      "Epoch [56200/100000], Loss: 0.9099\n",
      "Epoch [56300/100000], Loss: 0.8909\n",
      "Epoch [56400/100000], Loss: 0.8723\n",
      "Epoch [56500/100000], Loss: 0.8542\n",
      "Epoch [56600/100000], Loss: 0.8364\n",
      "Epoch [56700/100000], Loss: 0.8190\n",
      "Epoch [56800/100000], Loss: 0.8019\n",
      "Epoch [56900/100000], Loss: 0.7852\n",
      "Epoch [57000/100000], Loss: 0.7688\n",
      "Epoch [57100/100000], Loss: 0.7528\n",
      "Epoch [57200/100000], Loss: 0.7371\n",
      "Epoch [57300/100000], Loss: 0.7218\n",
      "Epoch [57400/100000], Loss: 0.7067\n",
      "Epoch [57500/100000], Loss: 0.6920\n",
      "Epoch [57600/100000], Loss: 0.6776\n",
      "Epoch [57700/100000], Loss: 0.6635\n",
      "Epoch [57800/100000], Loss: 0.6497\n",
      "Epoch [57900/100000], Loss: 0.6361\n",
      "Epoch [58000/100000], Loss: 0.6229\n",
      "Epoch [58100/100000], Loss: 0.6099\n",
      "Epoch [58200/100000], Loss: 0.5972\n",
      "Epoch [58300/100000], Loss: 0.5847\n",
      "Epoch [58400/100000], Loss: 0.5726\n",
      "Epoch [58500/100000], Loss: 0.5606\n",
      "Epoch [58600/100000], Loss: 0.5490\n",
      "Epoch [58700/100000], Loss: 0.5375\n",
      "Epoch [58800/100000], Loss: 0.5263\n",
      "Epoch [58900/100000], Loss: 0.5154\n",
      "Epoch [59000/100000], Loss: 0.5046\n",
      "Epoch [59100/100000], Loss: 0.4941\n",
      "Epoch [59200/100000], Loss: 0.4838\n",
      "Epoch [59300/100000], Loss: 0.4737\n",
      "Epoch [59400/100000], Loss: 0.4639\n",
      "Epoch [59500/100000], Loss: 0.4542\n",
      "Epoch [59600/100000], Loss: 0.4447\n",
      "Epoch [59700/100000], Loss: 0.4355\n",
      "Epoch [59800/100000], Loss: 0.4264\n",
      "Epoch [59900/100000], Loss: 0.4175\n",
      "Epoch [60000/100000], Loss: 0.4088\n",
      "Epoch [60100/100000], Loss: 0.4003\n",
      "Epoch [60200/100000], Loss: 0.3920\n",
      "Epoch [60300/100000], Loss: 0.3838\n",
      "Epoch [60400/100000], Loss: 0.3758\n",
      "Epoch [60500/100000], Loss: 0.3680\n",
      "Epoch [60600/100000], Loss: 0.3603\n",
      "Epoch [60700/100000], Loss: 0.3528\n",
      "Epoch [60800/100000], Loss: 0.3454\n",
      "Epoch [60900/100000], Loss: 0.3382\n",
      "Epoch [61000/100000], Loss: 0.3312\n",
      "Epoch [61100/100000], Loss: 0.3243\n",
      "Epoch [61200/100000], Loss: 0.3175\n",
      "Epoch [61300/100000], Loss: 0.3109\n",
      "Epoch [61400/100000], Loss: 0.3045\n",
      "Epoch [61500/100000], Loss: 0.2981\n",
      "Epoch [61600/100000], Loss: 0.2919\n",
      "Epoch [61700/100000], Loss: 0.2858\n",
      "Epoch [61800/100000], Loss: 0.2799\n",
      "Epoch [61900/100000], Loss: 0.2740\n",
      "Epoch [62000/100000], Loss: 0.2683\n",
      "Epoch [62100/100000], Loss: 0.2627\n",
      "Epoch [62200/100000], Loss: 0.2573\n",
      "Epoch [62300/100000], Loss: 0.2519\n",
      "Epoch [62400/100000], Loss: 0.2467\n",
      "Epoch [62500/100000], Loss: 0.2415\n",
      "Epoch [62600/100000], Loss: 0.2365\n",
      "Epoch [62700/100000], Loss: 0.2316\n",
      "Epoch [62800/100000], Loss: 0.2267\n",
      "Epoch [62900/100000], Loss: 0.2220\n",
      "Epoch [63000/100000], Loss: 0.2174\n",
      "Epoch [63100/100000], Loss: 0.2129\n",
      "Epoch [63200/100000], Loss: 0.2084\n",
      "Epoch [63300/100000], Loss: 0.2041\n",
      "Epoch [63400/100000], Loss: 0.1998\n",
      "Epoch [63500/100000], Loss: 0.1957\n",
      "Epoch [63600/100000], Loss: 0.1916\n",
      "Epoch [63700/100000], Loss: 0.1876\n",
      "Epoch [63800/100000], Loss: 0.1837\n",
      "Epoch [63900/100000], Loss: 0.1799\n",
      "Epoch [64000/100000], Loss: 0.1761\n",
      "Epoch [64100/100000], Loss: 0.1724\n",
      "Epoch [64200/100000], Loss: 0.1689\n",
      "Epoch [64300/100000], Loss: 0.1653\n",
      "Epoch [64400/100000], Loss: 0.1619\n",
      "Epoch [64500/100000], Loss: 0.1585\n",
      "Epoch [64600/100000], Loss: 0.1552\n",
      "Epoch [64700/100000], Loss: 0.1520\n",
      "Epoch [64800/100000], Loss: 0.1488\n",
      "Epoch [64900/100000], Loss: 0.1457\n",
      "Epoch [65000/100000], Loss: 0.1427\n",
      "Epoch [65100/100000], Loss: 0.1397\n",
      "Epoch [65200/100000], Loss: 0.1368\n",
      "Epoch [65300/100000], Loss: 0.1339\n",
      "Epoch [65400/100000], Loss: 0.1312\n",
      "Epoch [65500/100000], Loss: 0.1284\n",
      "Epoch [65600/100000], Loss: 0.1258\n",
      "Epoch [65700/100000], Loss: 0.1231\n",
      "Epoch [65800/100000], Loss: 0.1206\n",
      "Epoch [65900/100000], Loss: 0.1181\n",
      "Epoch [66000/100000], Loss: 0.1156\n",
      "Epoch [66100/100000], Loss: 0.1132\n",
      "Epoch [66200/100000], Loss: 0.1108\n",
      "Epoch [66300/100000], Loss: 0.1085\n",
      "Epoch [66400/100000], Loss: 0.1063\n",
      "Epoch [66500/100000], Loss: 0.1040\n",
      "Epoch [66600/100000], Loss: 0.1019\n",
      "Epoch [66700/100000], Loss: 0.0998\n",
      "Epoch [66800/100000], Loss: 0.0977\n",
      "Epoch [66900/100000], Loss: 0.0956\n",
      "Epoch [67000/100000], Loss: 0.0936\n",
      "Epoch [67100/100000], Loss: 0.0917\n",
      "Epoch [67200/100000], Loss: 0.0898\n",
      "Epoch [67300/100000], Loss: 0.0879\n",
      "Epoch [67400/100000], Loss: 0.0861\n",
      "Epoch [67500/100000], Loss: 0.0843\n",
      "Epoch [67600/100000], Loss: 0.0825\n",
      "Epoch [67700/100000], Loss: 0.0808\n",
      "Epoch [67800/100000], Loss: 0.0791\n",
      "Epoch [67900/100000], Loss: 0.0775\n",
      "Epoch [68000/100000], Loss: 0.0759\n",
      "Epoch [68100/100000], Loss: 0.0743\n",
      "Epoch [68200/100000], Loss: 0.0727\n",
      "Epoch [68300/100000], Loss: 0.0712\n",
      "Epoch [68400/100000], Loss: 0.0697\n",
      "Epoch [68500/100000], Loss: 0.0683\n",
      "Epoch [68600/100000], Loss: 0.0669\n",
      "Epoch [68700/100000], Loss: 0.0655\n",
      "Epoch [68800/100000], Loss: 0.0641\n",
      "Epoch [68900/100000], Loss: 0.0628\n",
      "Epoch [69000/100000], Loss: 0.0615\n",
      "Epoch [69100/100000], Loss: 0.0602\n",
      "Epoch [69200/100000], Loss: 0.0589\n",
      "Epoch [69300/100000], Loss: 0.0577\n",
      "Epoch [69400/100000], Loss: 0.0565\n",
      "Epoch [69500/100000], Loss: 0.0553\n",
      "Epoch [69600/100000], Loss: 0.0542\n",
      "Epoch [69700/100000], Loss: 0.0530\n",
      "Epoch [69800/100000], Loss: 0.0519\n",
      "Epoch [69900/100000], Loss: 0.0509\n",
      "Epoch [70000/100000], Loss: 0.0498\n",
      "Epoch [70100/100000], Loss: 0.0488\n",
      "Epoch [70200/100000], Loss: 0.0477\n",
      "Epoch [70300/100000], Loss: 0.0468\n",
      "Epoch [70400/100000], Loss: 0.0458\n",
      "Epoch [70500/100000], Loss: 0.0448\n",
      "Epoch [70600/100000], Loss: 0.0439\n",
      "Epoch [70700/100000], Loss: 0.0430\n",
      "Epoch [70800/100000], Loss: 0.0421\n",
      "Epoch [70900/100000], Loss: 0.0412\n",
      "Epoch [71000/100000], Loss: 0.0403\n",
      "Epoch [71100/100000], Loss: 0.0395\n",
      "Epoch [71200/100000], Loss: 0.0387\n",
      "Epoch [71300/100000], Loss: 0.0379\n",
      "Epoch [71400/100000], Loss: 0.0371\n",
      "Epoch [71500/100000], Loss: 0.0363\n",
      "Epoch [71600/100000], Loss: 0.0356\n",
      "Epoch [71700/100000], Loss: 0.0348\n",
      "Epoch [71800/100000], Loss: 0.0341\n",
      "Epoch [71900/100000], Loss: 0.0334\n",
      "Epoch [72000/100000], Loss: 0.0327\n",
      "Epoch [72100/100000], Loss: 0.0320\n",
      "Epoch [72200/100000], Loss: 0.0313\n",
      "Epoch [72300/100000], Loss: 0.0307\n",
      "Epoch [72400/100000], Loss: 0.0301\n",
      "Epoch [72500/100000], Loss: 0.0294\n",
      "Epoch [72600/100000], Loss: 0.0288\n",
      "Epoch [72700/100000], Loss: 0.0282\n",
      "Epoch [72800/100000], Loss: 0.0276\n",
      "Epoch [72900/100000], Loss: 0.0270\n",
      "Epoch [73000/100000], Loss: 0.0265\n",
      "Epoch [73100/100000], Loss: 0.0259\n",
      "Epoch [73200/100000], Loss: 0.0254\n",
      "Epoch [73300/100000], Loss: 0.0249\n",
      "Epoch [73400/100000], Loss: 0.0243\n",
      "Epoch [73500/100000], Loss: 0.0238\n",
      "Epoch [73600/100000], Loss: 0.0233\n",
      "Epoch [73700/100000], Loss: 0.0229\n",
      "Epoch [73800/100000], Loss: 0.0224\n",
      "Epoch [73900/100000], Loss: 0.0219\n",
      "Epoch [74000/100000], Loss: 0.0215\n",
      "Epoch [74100/100000], Loss: 0.0210\n",
      "Epoch [74200/100000], Loss: 0.0206\n",
      "Epoch [74300/100000], Loss: 0.0201\n",
      "Epoch [74400/100000], Loss: 0.0197\n",
      "Epoch [74500/100000], Loss: 0.0193\n",
      "Epoch [74600/100000], Loss: 0.0189\n",
      "Epoch [74700/100000], Loss: 0.0185\n",
      "Epoch [74800/100000], Loss: 0.0181\n",
      "Epoch [74900/100000], Loss: 0.0178\n",
      "Epoch [75000/100000], Loss: 0.0174\n",
      "Epoch [75100/100000], Loss: 0.0170\n",
      "Epoch [75200/100000], Loss: 0.0167\n",
      "Epoch [75300/100000], Loss: 0.0163\n",
      "Epoch [75400/100000], Loss: 0.0160\n",
      "Epoch [75500/100000], Loss: 0.0157\n",
      "Epoch [75600/100000], Loss: 0.0153\n",
      "Epoch [75700/100000], Loss: 0.0150\n",
      "Epoch [75800/100000], Loss: 0.0147\n",
      "Epoch [75900/100000], Loss: 0.0144\n",
      "Epoch [76000/100000], Loss: 0.0141\n",
      "Epoch [76100/100000], Loss: 0.0138\n",
      "Epoch [76200/100000], Loss: 0.0135\n",
      "Epoch [76300/100000], Loss: 0.0132\n",
      "Epoch [76400/100000], Loss: 0.0129\n",
      "Epoch [76500/100000], Loss: 0.0127\n",
      "Epoch [76600/100000], Loss: 0.0124\n",
      "Epoch [76700/100000], Loss: 0.0122\n",
      "Epoch [76800/100000], Loss: 0.0119\n",
      "Epoch [76900/100000], Loss: 0.0117\n",
      "Epoch [77000/100000], Loss: 0.0114\n",
      "Epoch [77100/100000], Loss: 0.0112\n",
      "Epoch [77200/100000], Loss: 0.0109\n",
      "Epoch [77300/100000], Loss: 0.0107\n",
      "Epoch [77400/100000], Loss: 0.0105\n",
      "Epoch [77500/100000], Loss: 0.0103\n",
      "Epoch [77600/100000], Loss: 0.0101\n",
      "Epoch [77700/100000], Loss: 0.0099\n",
      "Epoch [77800/100000], Loss: 0.0096\n",
      "Epoch [77900/100000], Loss: 0.0094\n",
      "Epoch [78000/100000], Loss: 0.0092\n",
      "Epoch [78100/100000], Loss: 0.0091\n",
      "Epoch [78200/100000], Loss: 0.0089\n",
      "Epoch [78300/100000], Loss: 0.0087\n",
      "Epoch [78400/100000], Loss: 0.0085\n",
      "Epoch [78500/100000], Loss: 0.0083\n",
      "Epoch [78600/100000], Loss: 0.0082\n",
      "Epoch [78700/100000], Loss: 0.0080\n",
      "Epoch [78800/100000], Loss: 0.0078\n",
      "Epoch [78900/100000], Loss: 0.0077\n",
      "Epoch [79000/100000], Loss: 0.0075\n",
      "Epoch [79100/100000], Loss: 0.0073\n",
      "Epoch [79200/100000], Loss: 0.0072\n",
      "Epoch [79300/100000], Loss: 0.0070\n",
      "Epoch [79400/100000], Loss: 0.0069\n",
      "Epoch [79500/100000], Loss: 0.0067\n",
      "Epoch [79600/100000], Loss: 0.0066\n",
      "Epoch [79700/100000], Loss: 0.0065\n",
      "Epoch [79800/100000], Loss: 0.0063\n",
      "Epoch [79900/100000], Loss: 0.0062\n",
      "Epoch [80000/100000], Loss: 0.0061\n",
      "Epoch [80100/100000], Loss: 0.0059\n",
      "Epoch [80200/100000], Loss: 0.0058\n",
      "Epoch [80300/100000], Loss: 0.0057\n",
      "Epoch [80400/100000], Loss: 0.0056\n",
      "Epoch [80500/100000], Loss: 0.0055\n",
      "Epoch [80600/100000], Loss: 0.0054\n",
      "Epoch [80700/100000], Loss: 0.0052\n",
      "Epoch [80800/100000], Loss: 0.0051\n",
      "Epoch [80900/100000], Loss: 0.0050\n",
      "Epoch [81000/100000], Loss: 0.0049\n",
      "Epoch [81100/100000], Loss: 0.0048\n",
      "Epoch [81200/100000], Loss: 0.0047\n",
      "Epoch [81300/100000], Loss: 0.0046\n",
      "Epoch [81400/100000], Loss: 0.0045\n",
      "Epoch [81500/100000], Loss: 0.0044\n",
      "Epoch [81600/100000], Loss: 0.0043\n",
      "Epoch [81700/100000], Loss: 0.0042\n",
      "Epoch [81800/100000], Loss: 0.0042\n",
      "Epoch [81900/100000], Loss: 0.0041\n",
      "Epoch [82000/100000], Loss: 0.0040\n",
      "Epoch [82100/100000], Loss: 0.0039\n",
      "Epoch [82200/100000], Loss: 0.0038\n",
      "Epoch [82300/100000], Loss: 0.0037\n",
      "Epoch [82400/100000], Loss: 0.0037\n",
      "Epoch [82500/100000], Loss: 0.0036\n",
      "Epoch [82600/100000], Loss: 0.0035\n",
      "Epoch [82700/100000], Loss: 0.0034\n",
      "Epoch [82800/100000], Loss: 0.0034\n",
      "Epoch [82900/100000], Loss: 0.0033\n",
      "Epoch [83000/100000], Loss: 0.0032\n",
      "Epoch [83100/100000], Loss: 0.0032\n",
      "Epoch [83200/100000], Loss: 0.0031\n",
      "Epoch [83300/100000], Loss: 0.0030\n",
      "Epoch [83400/100000], Loss: 0.0030\n",
      "Epoch [83500/100000], Loss: 0.0029\n",
      "Epoch [83600/100000], Loss: 0.0029\n",
      "Epoch [83700/100000], Loss: 0.0028\n",
      "Epoch [83800/100000], Loss: 0.0027\n",
      "Epoch [83900/100000], Loss: 0.0027\n",
      "Epoch [84000/100000], Loss: 0.0026\n",
      "Epoch [84100/100000], Loss: 0.0026\n",
      "Epoch [84200/100000], Loss: 0.0025\n",
      "Epoch [84300/100000], Loss: 0.0025\n",
      "Epoch [84400/100000], Loss: 0.0024\n",
      "Epoch [84500/100000], Loss: 0.0024\n",
      "Epoch [84600/100000], Loss: 0.0023\n",
      "Epoch [84700/100000], Loss: 0.0023\n",
      "Epoch [84800/100000], Loss: 0.0022\n",
      "Epoch [84900/100000], Loss: 0.0022\n",
      "Epoch [85000/100000], Loss: 0.0021\n",
      "Epoch [85100/100000], Loss: 0.0021\n",
      "Epoch [85200/100000], Loss: 0.0020\n",
      "Epoch [85300/100000], Loss: 0.0020\n",
      "Epoch [85400/100000], Loss: 0.0020\n",
      "Epoch [85500/100000], Loss: 0.0019\n",
      "Epoch [85600/100000], Loss: 0.0019\n",
      "Epoch [85700/100000], Loss: 0.0018\n",
      "Epoch [85800/100000], Loss: 0.0018\n",
      "Epoch [85900/100000], Loss: 0.0018\n",
      "Epoch [86000/100000], Loss: 0.0017\n",
      "Epoch [86100/100000], Loss: 0.0017\n",
      "Epoch [86200/100000], Loss: 0.0017\n",
      "Epoch [86300/100000], Loss: 0.0016\n",
      "Epoch [86400/100000], Loss: 0.0016\n",
      "Epoch [86500/100000], Loss: 0.0016\n",
      "Epoch [86600/100000], Loss: 0.0015\n",
      "Epoch [86700/100000], Loss: 0.0015\n",
      "Epoch [86800/100000], Loss: 0.0015\n",
      "Epoch [86900/100000], Loss: 0.0014\n",
      "Epoch [87000/100000], Loss: 0.0014\n",
      "Epoch [87100/100000], Loss: 0.0014\n",
      "Epoch [87200/100000], Loss: 0.0013\n",
      "Epoch [87300/100000], Loss: 0.0013\n",
      "Epoch [87400/100000], Loss: 0.0013\n",
      "Epoch [87500/100000], Loss: 0.0013\n",
      "Epoch [87600/100000], Loss: 0.0012\n",
      "Epoch [87700/100000], Loss: 0.0012\n",
      "Epoch [87800/100000], Loss: 0.0012\n",
      "Epoch [87900/100000], Loss: 0.0012\n",
      "Epoch [88000/100000], Loss: 0.0011\n",
      "Epoch [88100/100000], Loss: 0.0011\n",
      "Epoch [88200/100000], Loss: 0.0011\n",
      "Epoch [88300/100000], Loss: 0.0011\n",
      "Epoch [88400/100000], Loss: 0.0010\n",
      "Epoch [88500/100000], Loss: 0.0010\n",
      "Epoch [88600/100000], Loss: 0.0010\n",
      "Epoch [88700/100000], Loss: 0.0010\n",
      "Epoch [88800/100000], Loss: 0.0010\n",
      "Epoch [88900/100000], Loss: 0.0009\n",
      "Epoch [89000/100000], Loss: 0.0009\n",
      "Epoch [89100/100000], Loss: 0.0009\n",
      "Epoch [89200/100000], Loss: 0.0009\n",
      "Epoch [89300/100000], Loss: 0.0009\n",
      "Epoch [89400/100000], Loss: 0.0008\n",
      "Epoch [89500/100000], Loss: 0.0008\n",
      "Epoch [89600/100000], Loss: 0.0008\n",
      "Epoch [89700/100000], Loss: 0.0008\n",
      "Epoch [89800/100000], Loss: 0.0008\n",
      "Epoch [89900/100000], Loss: 0.0008\n",
      "Epoch [90000/100000], Loss: 0.0007\n",
      "Epoch [90100/100000], Loss: 0.0007\n",
      "Epoch [90200/100000], Loss: 0.0007\n",
      "Epoch [90300/100000], Loss: 0.0007\n",
      "Epoch [90400/100000], Loss: 0.0007\n",
      "Epoch [90500/100000], Loss: 0.0007\n",
      "Epoch [90600/100000], Loss: 0.0007\n",
      "Epoch [90700/100000], Loss: 0.0006\n",
      "Epoch [90800/100000], Loss: 0.0006\n",
      "Epoch [90900/100000], Loss: 0.0006\n",
      "Epoch [91000/100000], Loss: 0.0006\n",
      "Epoch [91100/100000], Loss: 0.0006\n",
      "Epoch [91200/100000], Loss: 0.0006\n",
      "Epoch [91300/100000], Loss: 0.0006\n",
      "Epoch [91400/100000], Loss: 0.0006\n",
      "Epoch [91500/100000], Loss: 0.0005\n",
      "Epoch [91600/100000], Loss: 0.0005\n",
      "Epoch [91700/100000], Loss: 0.0005\n",
      "Epoch [91800/100000], Loss: 0.0005\n",
      "Epoch [91900/100000], Loss: 0.0005\n",
      "Epoch [92000/100000], Loss: 0.0005\n",
      "Epoch [92100/100000], Loss: 0.0005\n",
      "Epoch [92200/100000], Loss: 0.0005\n",
      "Epoch [92300/100000], Loss: 0.0005\n",
      "Epoch [92400/100000], Loss: 0.0005\n",
      "Epoch [92500/100000], Loss: 0.0004\n",
      "Epoch [92600/100000], Loss: 0.0004\n",
      "Epoch [92700/100000], Loss: 0.0004\n",
      "Epoch [92800/100000], Loss: 0.0004\n",
      "Epoch [92900/100000], Loss: 0.0004\n",
      "Epoch [93000/100000], Loss: 0.0004\n",
      "Epoch [93100/100000], Loss: 0.0004\n",
      "Epoch [93200/100000], Loss: 0.0004\n",
      "Epoch [93300/100000], Loss: 0.0004\n",
      "Epoch [93400/100000], Loss: 0.0004\n",
      "Epoch [93500/100000], Loss: 0.0004\n",
      "Epoch [93600/100000], Loss: 0.0004\n",
      "Epoch [93700/100000], Loss: 0.0003\n",
      "Epoch [93800/100000], Loss: 0.0003\n",
      "Epoch [93900/100000], Loss: 0.0003\n",
      "Epoch [94000/100000], Loss: 0.0003\n",
      "Epoch [94100/100000], Loss: 0.0003\n",
      "Epoch [94200/100000], Loss: 0.0003\n",
      "Epoch [94300/100000], Loss: 0.0003\n",
      "Epoch [94400/100000], Loss: 0.0003\n",
      "Epoch [94500/100000], Loss: 0.0003\n",
      "Epoch [94600/100000], Loss: 0.0003\n",
      "Epoch [94700/100000], Loss: 0.0003\n",
      "Epoch [94800/100000], Loss: 0.0003\n",
      "Epoch [94900/100000], Loss: 0.0003\n",
      "Epoch [95000/100000], Loss: 0.0003\n",
      "Epoch [95100/100000], Loss: 0.0003\n",
      "Epoch [95200/100000], Loss: 0.0003\n",
      "Epoch [95300/100000], Loss: 0.0003\n",
      "Epoch [95400/100000], Loss: 0.0002\n",
      "Epoch [95500/100000], Loss: 0.0002\n",
      "Epoch [95600/100000], Loss: 0.0002\n",
      "Epoch [95700/100000], Loss: 0.0002\n",
      "Epoch [95800/100000], Loss: 0.0002\n",
      "Epoch [95900/100000], Loss: 0.0002\n",
      "Epoch [96000/100000], Loss: 0.0002\n",
      "Epoch [96100/100000], Loss: 0.0002\n",
      "Epoch [96200/100000], Loss: 0.0002\n",
      "Epoch [96300/100000], Loss: 0.0002\n",
      "Epoch [96400/100000], Loss: 0.0002\n",
      "Epoch [96500/100000], Loss: 0.0002\n",
      "Epoch [96600/100000], Loss: 0.0002\n",
      "Epoch [96700/100000], Loss: 0.0002\n",
      "Epoch [96800/100000], Loss: 0.0002\n",
      "Epoch [96900/100000], Loss: 0.0002\n",
      "Epoch [97000/100000], Loss: 0.0002\n",
      "Epoch [97100/100000], Loss: 0.0002\n",
      "Epoch [97200/100000], Loss: 0.0002\n",
      "Epoch [97300/100000], Loss: 0.0002\n",
      "Epoch [97400/100000], Loss: 0.0002\n",
      "Epoch [97500/100000], Loss: 0.0002\n",
      "Epoch [97600/100000], Loss: 0.0002\n",
      "Epoch [97700/100000], Loss: 0.0002\n",
      "Epoch [97800/100000], Loss: 0.0002\n",
      "Epoch [97900/100000], Loss: 0.0002\n",
      "Epoch [98000/100000], Loss: 0.0001\n",
      "Epoch [98100/100000], Loss: 0.0001\n",
      "Epoch [98200/100000], Loss: 0.0001\n",
      "Epoch [98300/100000], Loss: 0.0001\n",
      "Epoch [98400/100000], Loss: 0.0001\n",
      "Epoch [98500/100000], Loss: 0.0001\n",
      "Epoch [98600/100000], Loss: 0.0001\n",
      "Epoch [98700/100000], Loss: 0.0001\n",
      "Epoch [98800/100000], Loss: 0.0001\n",
      "Epoch [98900/100000], Loss: 0.0001\n",
      "Epoch [99000/100000], Loss: 0.0001\n",
      "Epoch [99100/100000], Loss: 0.0001\n",
      "Epoch [99200/100000], Loss: 0.0001\n",
      "Epoch [99300/100000], Loss: 0.0001\n",
      "Epoch [99400/100000], Loss: 0.0001\n",
      "Epoch [99500/100000], Loss: 0.0001\n",
      "Epoch [99600/100000], Loss: 0.0001\n",
      "Epoch [99700/100000], Loss: 0.0001\n",
      "Epoch [99800/100000], Loss: 0.0001\n",
      "Epoch [99900/100000], Loss: 0.0001\n",
      "Epoch [100000/100000], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# instantiate\n",
    "model = LeagueNN(\n",
    "    input_size = 190 * 2,\n",
    "    hidden_size = 10,\n",
    "    output_size = 190\n",
    ")\n",
    "\n",
    "# loss\n",
    "loss_criterion = nn.MSELoss() \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 100000\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(input_data_tensor)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = loss_criterion(outputs, target_rank_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()  # Zero gradients before backward pass\n",
    "    loss.backward()        # Compute gradients\n",
    "    optimizer.step()       # Update the weights\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:  # Print loss every 100 epochs\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test the trained model\n",
    "with torch.no_grad():  # No need to compute gradients during inference\n",
    "    predicted = model(input_data_tensor)\n",
    "    print(\"Predictions after training:\", predicted)\n",
    "    print(\"Actual target:\", target_rank_tensor)\n",
    "\n",
    "## TO DO: normalize input and output "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
